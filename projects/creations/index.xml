<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Creations on Tan Zhou</title>
    <link>/projects/creations/</link>
    <description>Recent content in Creations on Tan Zhou</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jan 2020 15:00:28 +0000</lastBuildDate>
    
	<atom:link href="/projects/creations/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Malaria detection using CNN and data augmentation</title>
      <link>/projects/creations/malaria_detection_cnn_healthcare/</link>
      <pubDate>Fri, 11 Sep 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/malaria_detection_cnn_healthcare/</guid>
      <description>Malaria classifiation using CNN and data augumentation Objective: The aim of this project is to distingulish if a person was infeacted with the Malaria from a microscopic image, and provide support for the lab examination results to quickly diagnosis the Malaria parasites.
Malaria Malaria is caused by Plasmodium parasites. The parasites are spread to people through the bites of infected female Anopheles mosquitoes, called &amp;ldquo;malaria vectors.&amp;rdquo;
Generally, the first symptoms of Malaria is fever, headache, and chills, but these symptoms usually appear after 10-15 days after the infective mosquito bite.</description>
    </item>
    
    <item>
      <title>Sentimental analysis of reviewers&#39; feedback using BERT vs. Machien learning</title>
      <link>/projects/creations/sentimental-analysis-of-reviewers-feedback-using-bert/</link>
      <pubDate>Tue, 01 Sep 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/sentimental-analysis-of-reviewers-feedback-using-bert/</guid>
      <description>Introduction Note: Retraining the BERT model took a long time using a local computer, to run in the Google Colab will be a good choice
Objectives To predict sentiment (postive, neutral, negeative) of customer feedback using tweet texts of differnt airline companies and compare different models&amp;rsquo;performace on text classification.
Specifically, multiple machine learing models such as KNN, Random forest and SVC have been used for conduct classification as a baseline. A new language representation model named BERT (Bidirectional Encoder Representations from Transformers) was also implemented to conduct sentiment analysis.</description>
    </item>
    
    <item>
      <title>Enhanced fraud detection using ML and PySpark framework with feature selection</title>
      <link>/projects/creations/enhanced_pyspark_ml_fraud_detection_feature_selection/</link>
      <pubDate>Tue, 11 Aug 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/enhanced_pyspark_ml_fraud_detection_feature_selection/</guid>
      <description>Introduction Goal To examplify the feature selection strategy in PySpark and furhter enhanc the pyspark pipeline&amp;rsquo;s performance on fraud detection.
In this project, I will continue to work on the data from the project fradu_detection_ML_PySpark. The data exploration will be same, and the feature selction will use input perturbation strtegry instead of PCA as I did in the previous project.
Why feature selection? 1. Curse of dimensionality â€” Overfitting
The common theme of the problems is that when the dimensionality increases, the volume of the space increases so fast that the available data become sparse.</description>
    </item>
    
    <item>
      <title>Fraud detection using ML and PySpark framework</title>
      <link>/projects/creations/pyspark_ml_fraud_detection/</link>
      <pubDate>Tue, 11 Aug 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/pyspark_ml_fraud_detection/</guid>
      <description>Introduction The image on the right was obtained from here.
There is a lack of public available datasets on financial services and specially in the emerging mobile money transactions domain. Financial datasets are important to many researchers and in particular to us performing research in the domain of fraud detection. Part of the problem is the intrinsically private nature of financial transactions, that leads to no publicly available datasets.
A synthetic dataset were generated using the simulator called PaySim.</description>
    </item>
    
    <item>
      <title>Ensemble models in PySpark</title>
      <link>/projects/creations/ensemble_model_pyspark/</link>
      <pubDate>Sat, 01 Aug 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/ensemble_model_pyspark/</guid>
      <description>Introduction Goal To examplify the uses of ensemble models in PySpark as the ensemble models in previous project using sklearn and keras and predict if the client will subscribe (yes/no) a term deposit (variable y) using market campaign data.
Ensemble models Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data.</description>
    </item>
    
    <item>
      <title>Bayesian Uncertainty for time series data (EVI) prediction using LSTM and autoencoder</title>
      <link>/projects/creations/bayesian-uncertainty-of-neutral-networks-lstm-for-time-series-analysis/</link>
      <pubDate>Sat, 11 Jul 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/bayesian-uncertainty-of-neutral-networks-lstm-for-time-series-analysis/</guid>
      <description>Introduction Bayesian NN How much confidence do you know about your model results or a paritcular prediction?
This is a critical important question for many business. With the advent of deep learning, many forecasting problems for business have been solved in innovative ways. For example, Uber researchers has provided a fascianting paper on time series prediction.
Standard deep learning method such as LSTM do not capture model uncertianty. However, the uncertianty estimation is indispensable for deep learning models.</description>
    </item>
    
    <item>
      <title>Time series analysis using ARIMA &amp; LSTM - MODIS</title>
      <link>/projects/creations/arima_vs._lstm_time_series_data/</link>
      <pubDate>Sat, 11 Jul 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/arima_vs._lstm_time_series_data/</guid>
      <description>Introduction ARIMA (Autoregressive integrated moving average) ARIMA can explain the time series pattern for given frequency or lag (hour, day and week &amp;hellip;) and also predict furhter values.
ARIMA analysis will focus on the logic of model and how to select the three important terms of the model: p is the order of the AR term,
q is the order of the MA term, d is the number of differencing required to make the time series stationary.</description>
    </item>
    
    <item>
      <title>Sentiment analysis for review classification using SWIVEL and a small datasets</title>
      <link>/projects/creations/nlp_swivel/</link>
      <pubDate>Mon, 01 Jun 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/nlp_swivel/</guid>
      <description>Introduction:
Genealy, it require an amount of data to train and a long time to train a NLP model for a specific dataset. Transfer learning is commonly used in this case to conduct the sentiment analsis for Natural Language Processing (NLP) problem.
Swivel performs approximate factorization of the point-wise mutual information matrix via stochastic gradient descent. It uses a piecewise loss with special handling for unobserved co-occurrences, and thus makes use of all the information in the matrix.</description>
    </item>
    
    <item>
      <title>Ensemble models for classification (combine deep learning with machine learning)</title>
      <link>/projects/creations/ensemble_models_classification/</link>
      <pubDate>Fri, 14 Feb 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/ensemble_models_classification/</guid>
      <description>Introduction:
Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction. As long as the base models are diverse and independent, the prediction error of the model decreases when the ensemble approach is used.</description>
    </item>
    
    <item>
      <title>Bayesian optimization deep learning</title>
      <link>/projects/creations/bayesian_optimziation_nn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects/creations/bayesian_optimziation_nn/</guid>
      <description>Introduction:
The picture of Bayesian optimization is obtianed from here
Bayesian optimization
There are a lot of hyperparameters for machine learning models such as NN. Typically, random or grid search are effecient ways to conduct the optimization of models. They can be very time-consuming in some cases which waste time on unpromising areas of search space. Bayesian optimization can overcome this problem by adopting an informed seach method in the space to find the optmized parameters.</description>
    </item>
    
    <item>
      <title>waveform decomposition vs. deconvolution</title>
      <link>/projects/creations/waveformlidar_processing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects/creations/waveformlidar_processing/</guid>
      <description>Goal:
Make waveform lidar processing become easier and enable users can use exisitng Discrete-return lidar data processing tools.
Introduction:
Waveform Light Detection and Ranging (LiDAR) data have advantages over discrete-return LiDAR data in accurately characterizing vegetation structure. However, we lack a comprehensive understanding of waveform data processing approaches under different topography and vegetation conditions. The objective of this paper is to highlight a novel deconvolution algorithm, the Gold algorithm, for processing waveform LiDAR data with optimal deconvolution parameters.</description>
    </item>
    
    <item>
      <title>Bayesian decompostion of waveform lidar and uncertaitny analysis</title>
      <link>/projects/creations/bayesian_decompostion/</link>
      <pubDate>Sat, 15 Feb 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/bayesian_decompostion/</guid>
      <description>The subsquent section is mainly to show how to quantify the uncertaity of waveform processing uinsg Bayesian method. The detailed description of the approach can refer to https://www.researchgate.net/publication/319018940_Bayesian_decomposition_of_full_waveform_LiDAR_data_with_uncertainty_analysis
In the domain of LiDAR applications, the observations or data are inherently subject to various errors such as system setting, system calibration, and range measurement errors. Additionally, the LiDAR vendors often do not clearly state what errors are considered when the data are provided.</description>
    </item>
    
  </channel>
</rss>