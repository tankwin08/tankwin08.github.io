<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pipeline on Tan Zhou</title>
    <link>/tags/pipeline/</link>
    <description>Recent content in pipeline on Tan Zhou</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Aug 2020 12:41:05 -0500</lastBuildDate>
    
	<atom:link href="/tags/pipeline/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Enhanced fraud detection using ML and PySpark framework with feature selection</title>
      <link>/projects/creations/enhanced_pyspark_ml_fraud_detection_feature_selection/</link>
      <pubDate>Tue, 11 Aug 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/enhanced_pyspark_ml_fraud_detection_feature_selection/</guid>
      <description>Introduction Goal To examplify the feature selection strategy in PySpark and furhter enhanc the pyspark pipeline&amp;rsquo;s performance on fraud detection.
In this project, I will continue to work on the data from the project fradu_detection_ML_PySpark. The data exploration will be same, and the feature selction will use input perturbation strtegry instead of PCA as I did in the previous project.
Why feature selection? 1. Curse of dimensionality â€” Overfitting
The common theme of the problems is that when the dimensionality increases, the volume of the space increases so fast that the available data become sparse.</description>
    </item>
    
    <item>
      <title>Ensemble models in PySpark</title>
      <link>/projects/creations/ensemble_model_pyspark/</link>
      <pubDate>Sat, 01 Aug 2020 12:41:05 -0500</pubDate>
      
      <guid>/projects/creations/ensemble_model_pyspark/</guid>
      <description>Introduction Ensemble models Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction. As long as the base models are diverse and independent, the prediction error of the model decreases when the ensemble approach is used.</description>
    </item>
    
  </channel>
</rss>