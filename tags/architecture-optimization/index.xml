<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Architecture Optimization on Tan Zhou</title>
    <link>/tags/architecture-optimization/</link>
    <description>Recent content in Architecture Optimization on Tan Zhou</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/tags/architecture-optimization/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Bayesian optimization deep learning</title>
      <link>/projects/creations/bayesian_optimziation_nn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects/creations/bayesian_optimziation_nn/</guid>
      <description>Introduction:
The picture of Bayesian optimization is obtianed from here
Bayesian optimization
There are a lot of hyperparameters for machine learning models such as NN. Typically, random or grid search are effecient ways to conduct the optimization of models. They can be very time-consuming in some cases which waste time on unpromising areas of search space. Bayesian optimization can overcome this problem by adopting an informed seach method in the space to find the optmized parameters.</description>
    </item>
    
  </channel>
</rss>